{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NSFFinal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "conda_tensorflow_p36",
      "language": "python",
      "name": "conda_tensorflow_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x7ga2OGQC220"
      },
      "source": [
        "# Natural Language Processing using Doc2Vec on National Science Foundation Awards Abstracts\n",
        "---\n",
        "### Team:  \n",
        "Jacob Noble  \n",
        "Himanshu Gamit  \n",
        "Shantanu Hadap\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tdOYaCrjC22-"
      },
      "source": [
        "### Imports\n",
        "\n",
        "sklearn's Standard Scaler should be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "12pVWFUTC22_",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "from gensim.models import Doc2Vec\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler # Replace with SAS version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HiqBFGEx4kNQ",
        "outputId": "29685a3c-3835-490e-a866-b2f6d25ff668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "!wget https://nsfdata.s3.amazonaws.com/nsfdataset.zip\n",
        "!unzip nsfdataset.zip -d data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-16 14:46:53--  https://nsfdata.s3.amazonaws.com/nsfdataset.zip\n",
            "Resolving nsfdata.s3.amazonaws.com (nsfdata.s3.amazonaws.com)... 52.216.16.176\n",
            "Connecting to nsfdata.s3.amazonaws.com (nsfdata.s3.amazonaws.com)|52.216.16.176|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 358656602 (342M) [application/zip]\n",
            "Saving to: ‘nsfdataset.zip’\n",
            "\n",
            "nsfdataset.zip      100%[===================>] 342.04M  35.8MB/s    in 10s     \n",
            "\n",
            "2020-04-16 14:47:04 (33.1 MB/s) - ‘nsfdataset.zip’ saved [358656602/358656602]\n",
            "\n",
            "Archive:  nsfdataset.zip\n",
            "  inflating: data/nsf_proposals.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ELme3JwFr579",
        "outputId": "60c0c11b-9150-45a7-a261-d0176933d6b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#import saspy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "selected_cols = ['abstractText','date']\n",
        "projects = pd.read_csv(\"data/nsf_proposals.csv\", usecols = selected_cols, nrows=30000, low_memory=False) #, nrows=30000\n",
        "print (\"Total Projects: \", projects.shape[0], \"\\nTotal Features: \", projects.shape[1])\n",
        "projects.date = pd.to_datetime(projects.date.str.replace('D', 'T'))\n",
        "projects = projects.sort_values('date')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Projects:  30000 \n",
            "Total Features:  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yPmscOBnC23B"
      },
      "source": [
        "### Load in Data using Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WpMB6ablC23C",
        "outputId": "d7dffdab-360b-4070-d863-772f4cd0c5e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "source": [
        "# Drop values without Abstract texts\n",
        "projects = projects.dropna(how='any')\n",
        "\n",
        "print(\"Max length of the abstractText:\", projects.abstractText.str.len().max())\n",
        "print(\"Min length of the abstractText:\", projects.abstractText.str.len().min())\n",
        "print(\"Avg length of the abstractText:\", projects.abstractText.apply(lambda x: len(x) - x.count(\" \")).mean())\n",
        "\n",
        "words = projects.abstractText.str.split().apply(len)\n",
        "print(\"Max words abstractText:\", words.max())\n",
        "projects.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length of the abstractText: 7977\n",
            "Min length of the abstractText: 1\n",
            "Avg length of the abstractText: 1524.8768992781024\n",
            "Max words abstractText: 1169\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abstractText</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A research and training center for quantitativ...</td>\n",
              "      <td>1988-08-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20002</th>\n",
              "      <td>Biotechnology is now recognized as a new focus...</td>\n",
              "      <td>1988-08-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25558</th>\n",
              "      <td>The Luquillo Experimental Forest (LEF) in Puer...</td>\n",
              "      <td>1988-10-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28891</th>\n",
              "      <td>An institute for atomic and molecular theory w...</td>\n",
              "      <td>1988-10-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27780</th>\n",
              "      <td>An institute for atomic and molecular theory w...</td>\n",
              "      <td>1988-10-12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            abstractText       date\n",
              "2      A research and training center for quantitativ... 1988-08-08\n",
              "20002  Biotechnology is now recognized as a new focus... 1988-08-24\n",
              "25558  The Luquillo Experimental Forest (LEF) in Puer... 1988-10-12\n",
              "28891  An institute for atomic and molecular theory w... 1988-10-12\n",
              "27780  An institute for atomic and molecular theory w... 1988-10-12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hJJZRTyCC23F"
      },
      "source": [
        "### Setup Training Set for Doc2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "puEINuT5C23F",
        "outputId": "ee4bd738-7544-4d88-cac6-7e5fe59d9055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_raw = projects.abstractText.str.lower().values\n",
        "num_of_docs = len(X_raw)\n",
        "print('Number of abstracts: ', num_of_docs)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of abstracts:  29090\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8ru1PXGUC23J"
      },
      "source": [
        "### Create generator that will tokenize the training abstracts on the fly to save on memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i1pg5829C23K",
        "colab": {}
      },
      "source": [
        "def doc_generator(input_docs_array):\n",
        "    for i, doc in enumerate(input_docs_array):\n",
        "        tokens = gensim.utils.simple_preprocess(doc)\n",
        "        yield gensim.models.doc2vec.TaggedDocument(tokens, [i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t7ZvV6OTC23Q",
        "colab": {}
      },
      "source": [
        "X = doc_generator(X_raw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AHy9VORiC23V"
      },
      "source": [
        "### Create Initial Doc2Vec Model and Training\n",
        "\n",
        "#### Skip to next section to work load in a pretrained model.  Training could take a potentially long time.\n",
        "\n",
        "We conduct the replication to Document Embedding with Paragraph Vectors (http://arxiv.org/abs/1507.07998). In this paper, they showed only DBOW results to NSF data. So we replicate this experiments using not only DBOW but also DM.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ArrJv_dvC23W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "e5ac4c70-8b29-4bc6-de7f-7dc1b252a475"
      },
      "source": [
        "%%time\n",
        "import multiprocessing\n",
        "from pprint import pprint\n",
        "cores = multiprocessing.cpu_count()\n",
        "\n",
        "#It is training 100 epochs in 300 dimension vector space\n",
        "models = [\n",
        "    # PV-DBOW \n",
        "    Doc2Vec(dm=0, dbow_words=1, size=300, window=8, min_count=1, iter=100, workers=cores),\n",
        "    # PV-DM w/average\n",
        "    #Doc2Vec(dm=1, dm_mean=1, size=300, window=8, min_count=1, iter =100, workers=cores),\n",
        "]\n",
        "\n",
        "models[0].build_vocab(doc_generator(X_raw))\n",
        "print(str(models[0]))\n",
        "#models[1].reset_from(models[0])\n",
        "#print(str(models[1]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/doc2vec.py:566: UserWarning: The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\n",
            "  warnings.warn(\"The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Doc2Vec(dbow+w,d300,n5,w8,s0.001,t2)\n",
            "CPU times: user 30.6 s, sys: 153 ms, total: 30.7 s\n",
            "Wall time: 30.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c5QCW4n32P7-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "42212ea2-54a7-4b7c-aa78-95ecb4b90be4"
      },
      "source": [
        "%%time \n",
        "for i, model in enumerate(models):\n",
        "    model.train(doc_generator(X_raw), total_examples=len(X_raw), epochs=model.iter)\n",
        "    model.save(str(i)+'nsf_doc2v.model')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 39s, sys: 531 ms, total: 2min 40s\n",
            "Wall time: 1min 24s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0BS4x08Y4T-_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6dddc6b-acd5-4dd6-ef0d-e692df17dd1b"
      },
      "source": [
        "print(\"Doc2Vec Embedding Shape:\",model.docvecs.vectors_docs.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Doc2Vec Embedding Shape: (29090, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mr5BKOvDC23c",
        "colab": {}
      },
      "source": [
        "# model.train(doc_generator(X_raw), total_examples=num_of_docs, epochs=1)\n",
        "# model.save('nsf_doc2vec.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gs7Qc0KOC23h"
      },
      "source": [
        "### Load Existing Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hJbB9-JzC23k",
        "outputId": "fc10c443-1d21-48cc-cb81-cee045bae332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "existing_model = '0nsf_doc2v.model' #'nsf_d2v_100.model' # Name of Existing model to load\n",
        "model = gensim.models.Doc2Vec.load(str(existing_model)) # Model is assumed to be in the shared folder"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "slapVISDC23n"
      },
      "source": [
        "### Testing Doc2Vec Model\n",
        "\n",
        "1. Infer Embedding Vecor for a New Abstract\n",
        "2. Generating Most Similar Articles based on document cluster. This is using cosine similary score.\n",
        "3. Storing the most similar files to S3 bucket.\n",
        "\n",
        "\n",
        "#### 1. Infer Embedding Vecor for a New Abstract\n",
        "\n",
        "First, calculating cosine similarity of New Text using Paragraph Vector. Word Vector and Document Vector are separately stored. We have to add .docvecs after model name to extract Document Vector from Doc2Vec Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_o5Knh0i6Qk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "d102ee6c-25f1-487f-a2b2-02f3a15bf574"
      },
      "source": [
        "!wget https://nsf-bucket.s3.us-east-2.amazonaws.com/input.txt"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-16 15:12:41--  https://nsf-bucket.s3.us-east-2.amazonaws.com/input.txt\n",
            "Resolving nsf-bucket.s3.us-east-2.amazonaws.com (nsf-bucket.s3.us-east-2.amazonaws.com)... 52.219.96.8\n",
            "Connecting to nsf-bucket.s3.us-east-2.amazonaws.com (nsf-bucket.s3.us-east-2.amazonaws.com)|52.219.96.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1758 (1.7K) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.72K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-16 15:12:41 (122 MB/s) - ‘input.txt’ saved [1758/1758]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEDLXN2-jSmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('./input.txt', 'rb') as file_stream:\n",
        "    text = file_stream.read().decode('utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4T1hmbghnFx",
        "colab_type": "code",
        "outputId": "5e310518-7b6c-41b1-b70d-4bf99915d4c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#text = \"\"\"This study utilizes publicly available data from the National Science Foundation (NSF) Web Application Programming Interface (API). In this paper, various machine learning techniques are demonstrated to explore, analyze and recommend similar proposal abstracts to aid the NSF or Awardee with the Merit Review Process. These techniques extract textual context and group it with similar context. The goal of the analysis was to utilize a Doc2Vec unsupervised learning algorithms to embed NSF funding proposal abstracts text into vector space.  Once vectorized, the abstracts were grouped together using K-means clustering. These techniques together proved to be successful at grouping similar proposals together and could be used to find similar proposals to newly submitted NSF funding proposals. To perform text analysis, SAS® University Edition is used which supports SASPy, SAS® Studio and Python JupyterLab. Gensim Doc2vec is used to generate document vectors for proposal abstracts. Afterwards, document vectors were used to cluster similar abstracts using SAS® Studio KMeans Clustering Module. For visualization, the abstract embeddings were reduced to two dimensions using Principal Component Analysis (PCA) within SAS® Studio. This was then compared to a t-Distributed Stochastic Neighbor Embedding (t-SNE) dimensionality reduction technique as part of the Scikit-learn machine learning toolkit for Python.Conclusively, NSF proposal abstract text analysis can help an awardee read and improve their proposal model by identifying similar proposal abstracts from the last 24 years. It could also help NSF evaluators identify similar existing proposals that indirectly provides insights on whether a new proposal is going to be fruitful or not.\"\"\"\n",
        "print(text)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This study utilizes publicly available data from the National Science Foundation (NSF) Web Application Programming Interface (API). In this paper, various machine learning techniques are demonstrated to explore, analyze and recommend similar proposal abstracts to aid the NSF or Awardee with the Merit Review Process. These techniques extract textual context and group it with similar context. The goal of the analysis was to utilize a Doc2Vec unsupervised learning algorithms to embed NSF funding proposal abstracts text into vector space.  Once vectorized, the abstracts were grouped together using K-means clustering. These techniques together proved to be successful at grouping similar proposals together and could be used to find similar proposals to newly submitted NSF funding proposals. \r\n",
            "To perform text analysis, SAS® University Edition is used which supports SASPy, SAS® Studio and Python JupyterLab. Gensim Doc2vec is used to generate document vectors for proposal abstracts. Afterwards, document vectors were used to cluster similar abstracts using SAS® Studio KMeans Clustering Module. For visualization, the abstract embeddings were reduced to two dimensions using Principal Component Analysis (PCA) within SAS® Studio. This was then compared to a t-Distributed Stochastic Neighbor Embedding (t-SNE) dimensionality reduction technique as part of the Scikit-learn machine learning toolkit for Python.\r\n",
            "Conclusively, NSF proposal abstract text analysis can help an awardee read and improve their proposal model by identifying similar proposal abstracts from the last 24 years. It could also help NSF evaluators identify similar existing proposals that indirectly provides insights on whether a new proposal is going to be fruitful or not.\r\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9UVA8d2kC23o",
        "colab": {}
      },
      "source": [
        "test_vector = model.infer_vector(gensim.utils.simple_preprocess(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "woPjuZXDC23s",
        "outputId": "a03d413f-1391-4a0d-e9c4-dc4544c227cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_vector"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.8438365 , -0.17401043, -0.13399816, -0.2000463 ,  0.13937432,\n",
              "        0.23570478,  0.09454932,  0.57916385,  0.23849203, -0.17535031,\n",
              "        1.3722361 , -1.0783211 ,  0.270243  , -0.97854984,  0.8234382 ,\n",
              "        0.02699925, -0.4561137 , -0.00563184, -0.5500358 , -0.47532412,\n",
              "        0.4896474 , -1.061523  ,  0.41433418, -0.33881608, -0.50388104,\n",
              "        0.13778783,  0.7151214 ,  0.38627973,  0.26692402,  0.78165257,\n",
              "        0.3631258 ,  0.31219473, -0.06193725,  0.1172061 ,  0.36414784,\n",
              "        0.35421765, -0.13689107, -0.45280287,  0.80544066, -0.41016334,\n",
              "       -0.6796709 ,  0.16536756, -0.04947023,  0.36030695,  0.02316136,\n",
              "       -0.14729203, -0.5510913 ,  0.4065121 , -0.2794985 ,  0.44954312,\n",
              "       -0.6153437 , -0.15876888, -0.92806524,  1.0740391 ,  0.7172982 ,\n",
              "       -0.96308166,  0.13134834,  1.0354185 ,  0.28054276, -0.7680927 ,\n",
              "        0.5887584 , -1.5406504 ,  0.10726024, -0.01891238, -0.41754752,\n",
              "        0.04708375, -0.9622146 , -0.40153816, -0.83389646,  0.5060825 ,\n",
              "       -0.5461605 , -0.1186926 ,  0.5306065 ,  0.5396477 ,  0.02342715,\n",
              "       -0.38910058,  0.40449658,  0.08066926, -0.06879188,  0.2860055 ,\n",
              "        0.04396184, -0.46605107,  0.33744848, -0.05516233, -0.5006645 ,\n",
              "        0.86801386,  0.53460187, -0.76466495,  0.42543364,  1.1542464 ,\n",
              "       -0.4054096 , -0.11083125,  0.31503072, -0.7594034 , -0.5548555 ,\n",
              "       -0.26868165,  0.41146198, -0.40678453, -1.5761169 ,  1.1942182 ,\n",
              "       -0.05122133,  0.4272175 ,  0.6224018 , -0.05621269, -0.34011447,\n",
              "       -0.07995248, -0.3676434 , -0.33112273,  0.671225  ,  0.31315383,\n",
              "       -0.3005118 , -0.5901006 , -0.2109417 ,  0.8301641 , -0.5111019 ,\n",
              "       -0.6816803 , -0.26336953, -0.6830891 ,  0.2215421 ,  0.05362492,\n",
              "        0.13382426, -0.23218314,  0.17721634,  0.2725952 , -0.70052093,\n",
              "        0.2404046 ,  0.31983116,  0.2851704 , -0.38122505, -0.4115964 ,\n",
              "        0.05272647, -0.22568582, -0.14227441, -0.23342124, -0.07755499,\n",
              "       -0.08270889, -0.7574143 , -1.0452653 ,  0.43399176, -0.3445039 ,\n",
              "       -0.56972665, -0.9125309 ,  0.767997  , -0.35348034,  0.09645507,\n",
              "        1.0325639 ,  0.04972064,  0.49917093, -0.00302436, -0.8625937 ,\n",
              "       -1.2689568 , -0.00323239,  0.2828421 , -0.78075767, -0.13463055,\n",
              "       -0.12746704, -0.47406858, -1.1991757 ,  0.4291418 , -0.8649341 ,\n",
              "       -0.14196783,  0.91953176, -0.57328516,  0.09285727, -0.85092604,\n",
              "       -0.30698985,  0.33811158, -0.45686087,  0.48637214,  0.87527966,\n",
              "       -0.33482906, -0.0148897 ,  0.82818127, -0.5906365 , -0.4366415 ,\n",
              "       -0.6951651 , -0.08029774,  0.00237092, -0.7608371 ,  1.0059803 ,\n",
              "       -0.23993886,  1.0446808 , -0.49804652, -0.23114477,  0.83300793,\n",
              "       -0.040885  , -1.2810606 , -0.17066503,  0.45657307,  0.53540456,\n",
              "        0.18233424,  0.36011454,  1.0506915 , -0.3040775 ,  0.1283103 ,\n",
              "        0.2722251 , -1.3659583 , -0.5419152 ,  0.6302877 ,  0.843455  ,\n",
              "       -0.31452736, -0.8929847 , -0.08420274,  0.8095014 , -0.8600603 ,\n",
              "        0.775461  ,  0.6225544 ,  0.35979795,  0.6736297 ,  0.25922185,\n",
              "        0.10229518, -0.8101552 ,  0.4780841 , -0.36353013,  1.0716535 ,\n",
              "       -0.27776626,  0.9815046 ,  1.248002  ,  0.14910191,  0.10587306,\n",
              "       -0.27634582,  0.8325432 , -0.09366204, -0.968332  , -0.813449  ,\n",
              "       -0.79244906,  1.019368  ,  0.40777677,  0.7851484 , -0.5808539 ,\n",
              "        1.2769654 , -1.0272874 ,  0.29460967,  0.5709362 ,  0.47537988,\n",
              "        0.74359304,  0.8055401 , -0.15039131, -0.88986653,  0.74181604,\n",
              "       -0.54860383, -0.4078014 , -0.14424652,  0.28695685,  0.18561028,\n",
              "        0.2714243 , -0.98999065,  0.19817357, -0.03668776,  0.4286655 ,\n",
              "        0.43200555, -0.3689143 ,  1.0261714 , -0.74383307,  0.10492644,\n",
              "       -1.2470597 ,  0.87720865,  1.0535936 , -0.7218246 , -0.52794015,\n",
              "       -0.12661949, -0.57672715,  0.0082891 , -0.08920021,  0.60259587,\n",
              "        0.2633735 ,  0.06799236, -0.6161591 , -1.435106  ,  0.30595136,\n",
              "        0.15995374, -0.313622  ,  0.54083616,  1.0082811 , -0.23796862,\n",
              "        0.18103406, -0.17701158,  0.03261626,  0.18646392,  0.28413   ,\n",
              "        0.80489993, -0.57016397, -0.1258045 ,  0.32598218, -0.63598526,\n",
              "        0.49304837,  0.36666328, -0.5996964 ,  0.8229917 , -0.3717598 ,\n",
              "       -0.5471667 ,  0.08718269, -0.8069634 , -0.85535264, -0.54932743,\n",
              "        0.8142086 ,  0.19056846,  0.09502913,  0.2735444 ,  1.0825301 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ukx9sWJfjCa",
        "colab_type": "text"
      },
      "source": [
        "#### 2. Generating Most Similar Articles based on document cluster. This is using cosine similary score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MZ8dZDfPC23v",
        "outputId": "d336034e-4a84-4b74-f430-9dad9bd712ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "model.docvecs.most_similar(\n",
        "    positive=[test_vector], \n",
        "    topn=3)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(28343, 0.2686604857444763),\n",
              " (28391, 0.2660232186317444),\n",
              " (28587, 0.26435062289237976)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw_EKxCmfzZT",
        "colab_type": "text"
      },
      "source": [
        "3. Storing the most similar files to S3 bucket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vnnZTNlBIWTT",
        "colab": {}
      },
      "source": [
        "file = open('top1.txt', 'w',encoding=\"utf-8\")\n",
        "file.write(X_raw[289674])\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WX7zmH6oC23y",
        "colab": {}
      },
      "source": [
        "file = open('top2.txt', 'w',encoding=\"utf-8\")\n",
        "file.write(X_raw[258922])\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5FWQ2EF8C24H",
        "colab": {}
      },
      "source": [
        "file = open('top3.txt', 'w',encoding=\"utf-8\")\n",
        "file.write(X_raw[24392])\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2G0n0VRaC24J",
        "colab": {}
      },
      "source": [
        "### Text summerizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjVXD-4jhnGK",
        "colab_type": "text"
      },
      "source": [
        "### Create the session\n",
        "\n",
        "The session remembers our connection parameters to SageMaker. We'll use it to perform all of our SageMaker operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f816d871-9c3b-4244-cc39-d0105cdc2150",
        "id": "ThbzqpNFkEeS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "import sagemaker as sage\n",
        "from time import gmtime, strftime\n",
        "from sagemaker import get_execution_role\n",
        "\n",
        "sess = sage.Session()\n",
        "role = get_execution_role()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-6453753ca282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msagemaker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_execution_role\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mrole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_execution_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, boto_session, sagemaker_client, sagemaker_runtime_client, default_bucket)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mboto_session\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboto_session\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0msagemaker_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         )\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, boto_session, sagemaker_client, sagemaker_runtime_client)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_region_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             raise ValueError(\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0;34m\"Must setup local AWS configuration with a region supported by SageMaker.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             )\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Must setup local AWS configuration with a region supported by SageMaker."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTTJoGXrhnGM",
        "colab_type": "text"
      },
      "source": [
        "## Create Model\n",
        "\n",
        "Now we use the Model Package to create a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VdfpjcehnGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please use the appropriate ARN obtained after subscribing to the model to define 'model_package_arn'\n",
        "model_package_arn = 'arn:aws:sagemaker:us-east-2:057799348421:model-package/marketplace-text-summarizer-11-d2490248e8de20f24ae3b72d0d74654c'\n",
        "from sagemaker import ModelPackage\n",
        "import sagemaker as sage\n",
        "from sagemaker import get_execution_role\n",
        "\n",
        "role = get_execution_role()\n",
        "sagemaker_session = sage.Session()\n",
        "model = ModelPackage(model_package_arn=model_package_arn,\n",
        "                    role = role,\n",
        "                    sagemaker_session = sagemaker_session)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPPl9wQ-hnGP",
        "colab_type": "text"
      },
      "source": [
        "## Input File\n",
        "\n",
        "Now we pull a sample input file for testing the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRE7YW7yhnGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top1_txt=\"s3://nsf/top1.txt\"\n",
        "top2_txt=\"s3://nsf/top2.txt\"\n",
        "top3_txt=\"s3://nsf/top3.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rBN7cQLhnGU",
        "colab_type": "text"
      },
      "source": [
        "## Batch Transform Job\n",
        "\n",
        "Now let's use the model built to run a batch inference job and verify it works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ul_Wsbb1hnGV",
        "colab_type": "code",
        "outputId": "7d3504fe-061d-4179-c793-350ad57e0cb7",
        "colab": {}
      },
      "source": [
        "import json \n",
        "import uuid\n",
        "transformer = model.transformer(2, 'ml.m5.xlarge')\n",
        "transformer.output_path = \"s3://nsf/Summerized\"\n",
        "transformer.transform(top2_txt, content_type='text/plain')\n",
        "transformer.wait()\n",
        "print(\"Batch Transform complete\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using already existing model: marketplace-text-summarizer-11-d2490248-2020-04-15-19-31-40-147\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "..........................\u001b[34m2020-04-15T20:22:02.869:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
            "\u001b[33m * Serving Flask app \"serve\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: off\n",
            " * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\u001b[0m\n",
            "\u001b[33m169.254.255.130 - - [15/Apr/2020 20:22:02] \"#033[37mGET /ping HTTP/1.1#033[0m\" 200 -\u001b[0m\n",
            "\u001b[33m169.254.255.130 - - [15/Apr/2020 20:22:02] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
            "\u001b[35m2020-04-15T20:22:09.872:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
            "\u001b[36m2020-04-15T20:22:09.872:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
            "\u001b[34m * Serving Flask app \"serve\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: off\n",
            " * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\u001b[0m\n",
            "\u001b[34m169.254.255.130 - - [15/Apr/2020 20:22:09] \"#033[37mGET /ping HTTP/1.1#033[0m\" 200 -\u001b[0m\n",
            "\u001b[34m169.254.255.130 - - [15/Apr/2020 20:22:09] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
            "\u001b[34m---input--- numerical and asymptotic techniques will be used to                        investigate transonic flow about aircraft wings and flows with                  distributed vorticity.  specific transonic problems to be                       analyzed are design of optimum critical axisymmetric bodies,                    flows about lifting, not-so-slender transonic wings and the                     transonic area rule, and wind tunnel flows.  some use will be                   made of the transonic small disturbance formulation.  the                       investigations of the vortical flow problem will involve                        development and clarification of theories integrating nonlinear                 and viscous effects.  both the transonic and vortical flow                      problems require interaction between numerical and asymptotic                   treatments in order to deal with complex nonlinearities.                             present day commercial aircraft cruise in the transonic                    regime.  in this regime drag (the force opposing forward motion)                rises rapidly hence there is interest in understanding transonic                flows and in the design of reduced drag wings.  the study of                    flows with distributed vorticity (a certain distribution of                     whirl-like motion in the environment of interest) is both of a                  fundamental nature in fluid mechanics, but also of considerable                 interest in specific applications.  one example of such an                      application is the prediction of aerodynamic losses and heat                    loads in turbo-machinery.  the investigators will use modern                    methods of applied mathematics to deal with the complexities of                 the problems in the areas of research proposed.\u001b[0m\n",
            "\u001b[32m * Serving Flask app \"serve\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: off\n",
            " * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\u001b[0m\n",
            "\u001b[32m169.254.255.130 - - [15/Apr/2020 20:22:09] \"#033[37mGET /ping HTTP/1.1#033[0m\" 200 -\u001b[0m\n",
            "\u001b[32m169.254.255.130 - - [15/Apr/2020 20:22:09] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
            "\u001b[32m---input--- numerical and asymptotic techniques will be used to                        investigate transonic flow about aircraft wings and flows with                  distributed vorticity.  specific transonic problems to be                       analyzed are design of optimum critical axisymmetric bodies,                    flows about lifting, not-so-slender transonic wings and the                     transonic area rule, and wind tunnel flows.  some use will be                   made of the transonic small disturbance formulation.  the                       investigations of the vortical flow problem will involve                        development and clarification of theories integrating nonlinear                 and viscous effects.  both the transonic and vortical flow                      problems require interaction between numerical and asymptotic                   treatments in order to deal with complex nonlinearities.                             present day commercial aircraft cruise in the transonic                    regime.  in this regime drag (the force opposing forward motion)                rises rapidly hence there is interest in understanding transonic                flows and in the design of reduced drag wings.  the study of                    flows with distributed vorticity (a certain distribution of                     whirl-like motion in the environment of interest) is both of a                  fundamental nature in fluid mechanics, but also of considerable                 interest in specific applications.  one example of such an                      application is the prediction of aerodynamic losses and heat                    loads in turbo-machinery.  the investigators will use modern                    methods of applied mathematics to deal with the complexities of                 the problems in the areas of research proposed.\u001b[0m\n",
            "\u001b[34m----in bert text to json--------- [{'src': [['numerical', 'and', 'asymptotic', 'techniques', 'will', 'be', 'used', 'to', 'investigate', 'transonic', 'flow', 'about', 'aircraft', 'wings', 'and', 'flows', 'with', 'distributed', 'vorticity', '.'], ['specific', 'transonic', 'problems', 'to', 'be', 'analyzed', 'are', 'design', 'of', 'optimum', 'critical', 'axisymmetric', 'bodies', ',', 'flows', 'about', 'lifting', ',', 'not-so-slender', 'transonic', 'wings', 'and', 'the', 'transonic', 'area', 'rule', ',', 'and', 'wind', 'tunnel', 'flows', '.'], ['some', 'use', 'will', 'be', 'made', 'of', 'the', 'transonic', 'small', 'disturbance', 'formulation', '.'], ['the', 'investigations', 'of', 'the', 'vortical', 'flow', 'problem', 'will', 'involve', 'development', 'and', 'clarification', 'of', 'theories', 'integrating', 'nonlinear', 'and', 'viscous', 'effects', '.'], ['both', 'the', 'transonic', 'and', 'vortical', 'flow', 'problems', 'require', 'interaction', 'between', 'numerical', 'and', 'asymptotic', 'treatments', 'in', 'order', 'to', 'deal', 'with', 'complex', 'nonlinearities', '.'], ['present', 'day', 'commercial', 'aircraft', 'cruise', 'in', 'the', 'transonic', 'regime', '.'], ['in', 'this', 'regime', 'drag', '(', 'the', 'force', 'opposing', 'forward', 'motion', ')', 'rises', 'rapidly', 'hence', 'there', 'is', 'interest', 'in', 'understanding', 'transonic', 'flows', 'and', 'in', 'the', 'design', 'of', 'reduced', 'drag', 'wings', '.'], ['the', 'study', 'of', 'flows', 'with', 'distributed', 'vorticity', '(', 'a', 'certain', 'distribution', 'of', 'whirl-like', 'motion', 'in', 'the', 'environment', 'of', 'interest', ')', 'is', 'both', 'of', 'a', 'fundamental', 'nature', 'in', 'fluid', 'mechanics', ',', 'but', 'also', 'of', 'considerable', 'interest', 'in', 'specific', 'applications', '.'], ['one', 'example', 'of', 'such', 'an', 'application', 'is', 'the', 'prediction', 'of', 'aerodynamic', 'losses', 'and', 'heat', 'loads', 'in', 'turbo-machinery', '.'], ['the', 'investigators', 'will', 'use', 'modern', 'methods', 'of', 'applied', 'mathematics', 'to', 'deal', 'with', 'the', 'complexities', 'of', 'the', 'problems', 'in', 'the', 'areas', 'of', 'research', 'proposed', '.']], 'tgt': [['no', 'summary', 'found']]}]\u001b[0m\n",
            "\u001b[34m[]\u001b[0m\n",
            "\u001b[34m[('../json_data/cnndm.valid.0.json', Namespace(dataset='', log_file='../logs/preprocess.log', lower=True, map_path='../data/', max_nsents=100, max_src_ntokens=200, min_nsents=3, min_src_ntokens=5, mode='format_to_bert', n_cpus=4, oracle_mode='greedy', raw_path='../json_data', save_path='../json_data', shard_size=2000), '../json_data/cnndm.valid.0.bert.pt')]\u001b[0m\n",
            "\u001b[34m[2020-04-15 20:22:10,583 INFO] loading vocabulary file ../json_data/vocab.txt\u001b[0m\n",
            "\u001b[34m[2020-04-15 20:22:10,611 INFO] Processing ../json_data/cnndm.valid.0.json\u001b[0m\n",
            "\u001b[34m[2020-04-15 20:22:10,615 INFO] Saving to ../json_data/cnndm.valid.0.bert.pt\u001b[0m\n",
            "\u001b[34m[('../json_data/cnndm.test.0.json', Namespace(dataset='', log_file='../logs/preprocess.log', lower=True, map_path='../data/', max_nsents=100, max_src_ntokens=200, min_nsents=3, min_src_ntokens=5, mode='format_to_bert', n_cpus=4, oracle_mode='greedy', raw_path='../json_data', save_path='../json_data', shard_size=2000), '../json_data/cnndm.test.0.bert.pt')]\u001b[0m\n",
            "\u001b[34m[2020-04-15 20:22:10,693 INFO] loading vocabulary file ../json_data/vocab.txt\u001b[0m\n",
            "\u001b[34m[2020-04-15 20:22:10,720 INFO] Processing ../json_data/cnndm.test.0.json\u001b[0m\n",
            "\u001b[34m[2020-04-15 20:22:10,725 INFO] Saving to ../json_data/cnndm.test.0.bert.pt\u001b[0m\n",
            "\u001b[34mlook at me: ../json_data/cnndm test\u001b[0m\n",
            "\u001b[34mfiles found :  ['../json_data/cnndm.test.0.bert.pt']\u001b[0m\n",
            "\u001b[34mgpu_rank 0\u001b[0m\n",
            "\u001b[34m------------inside train.py test_iter---------------- <models.data_loader.Dataloader object at 0x7f56c63f5b00>\u001b[0m\n",
            "\u001b[34m---------------sent_scores-------------- tensor([[0.6225, 0.2962, 0.2188, 0.2055, 0.1864, 0.0588, 0.0510, 0.0561, 0.0258,\n",
            "         0.1015]])\u001b[0m\n",
            "\u001b[34m---------------mask--------------------- tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=torch.uint8)\u001b[0m\n",
            "\u001b[34m-----------------inside train.py pred------------------ ['numerical and asymptotic techniques will be used to investigate transonic flow about aircraft wings and flows with distributed vorticity .<q>specific transonic problems to be analyzed are design of optimum critical axisymmetric bodies , flows about lifting , not-so-slender transonic wings and the transonic area rule , and wind tunnel flows .<q>some use will be made of the transonic small disturbance formulation .']\u001b[0m\n",
            "\u001b[34m-----------------inside train.py gold------------------ ['no summary found']\u001b[0m\n",
            "\u001b[34m<_io.TextIOWrapper name='../json_data/results/_step50000.candidate' mode='w' encoding='ANSI_X3.4-1968'>\u001b[0m\n",
            "\u001b[34m-----combined----- numerical and asymptotic techniques will be used to investigate transonic flow about aircraft wings and flows with distributed vorticity .<q>specific transonic problems to be analyzed are design of optimum critical axisymmetric bodies , flows about lifting , not-so-slender transonic wings and the transonic area rule , and wind tunnel flows .<q>some use will be made of the transonic small disturbance formulation .\n",
            "\u001b[0m\n",
            "\u001b[34m---------------intermediate---------- numerical and asymptotic techniques will be used to investigate transonic flow about aircraft wings and flows with distributed vorticity .<q>specific transonic problems to be analyzed are design of optimum critical axisymmetric bodies , flows about lifting , not-so-slender transonic wings and the transonic area rule , and wind tunnel flows .<q>some use will be made of the transonic small disturbance formulation .\n",
            "\u001b[0m\n",
            "\u001b[34m------------in pretty summary----------------- numerical and asymptotic techniques will be used to investigate transonic flow about aircraft wings and flows with distributed vorticity .<q>specific transonic problems to be analyzed are design of optimum critical axisymmetric bodies , flows about lifting , not-so-slender transonic wings and the transonic area rule , and wind tunnel flows .<q>some use will be made of the transonic small disturbance formulation .\n",
            "\u001b[0m\n",
            "\u001b[34m------------------result------------- Numerical and asymptotic techniques will be used to investigate transonic flow about aircraft wings and flows with distributed vorticity. Specific transonic problems to be analyzed are design of optimum critical axisymmetric bodies , flows about lifting , not-so-slender transonic wings and the transonic area rule , and wind tunnel flows. Some use will be made of the transonic small disturbance formulation.\u001b[0m\n",
            "\u001b[34m169.254.255.130 - - [15/Apr/2020 20:22:11] \"#033[37mPOST /invocations HTTP/1.1#033[0m\" 200 -\u001b[0m\n",
            "\u001b[32m----in bert text to json--------- [{'src': [['numerical', 'and', 'asymptotic', 'techniques', 'will', 'be', 'used', 'to', 'investigate', 'transonic', 'flow', 'about', 'aircraft', 'wings', 'and', 'flows', 'with', 'distributed', 'vorticity', '.'], ['specific', 'transonic', 'problems', 'to', 'be', 'analyzed', 'are', 'design', 'of', 'optimum', 'critical', 'axisymmetric', 'bodies', ',', 'flows', 'about', 'lifting', ',', 'not-so-slender', 'transonic', 'wings', 'and', 'the', 'transonic', 'area', 'rule', ',', 'and', 'wind', 'tunnel', 'flows', '.'], ['some', 'use', 'will', 'be', 'made', 'of', 'the', 'transonic', 'small', 'disturbance', 'formulation', '.'], ['the', 'investigations', 'of', 'the', 'vortical', 'flow', 'problem', 'will', 'involve', 'development', 'and', 'clarification', 'of', 'theories', 'integrating', 'nonlinear', 'and', 'viscous', 'effects', '.'], ['both', 'the', 'transonic', 'and', 'vortical', 'flow', 'problems', 'require', 'interaction', 'between', 'numerical', 'and', 'asymptotic', 'treatments', 'in', 'order', 'to', 'deal', 'with', 'complex', 'nonlinearities', '.'], ['present', 'day', 'commercial', 'aircraft', 'cruise', 'in', 'the', 'transonic', 'regime', '.'], ['in', 'this', 'regime', 'drag', '(', 'the', 'force', 'opposing', 'forward', 'motion', ')', 'rises', 'rapidly', 'hence', 'there', 'is', 'interest', 'in', 'understanding', 'transonic', 'flows', 'and', 'in', 'the', 'design', 'of', 'reduced', 'drag', 'wings', '.'], ['the', 'study', 'of', 'flows', 'with', 'distributed', 'vorticity', '(', 'a', 'certain', 'distribution', 'of', 'whirl-like', 'motion', 'in', 'the', 'environment', 'of', 'interest', ')', 'is', 'both', 'of', 'a', 'fundamental', 'nature', 'in', 'fluid', 'mechanics', ',', 'but', 'also', 'of', 'considerable', 'interest', 'in', 'specific', 'applications', '.'], ['one', 'example', 'of', 'such', 'an', 'application', 'is', 'the', 'prediction', 'of', 'aerodynamic', 'losses', 'and', 'heat', 'loads', 'in', 'turbo-machinery', '.'], ['the', 'investigators', 'will', 'use', 'modern', 'methods', 'of', 'applied', 'mathematics', 'to', 'deal', 'with', 'the', 'complexities', 'of', 'the', 'problems', 'in', 'the', 'areas', 'of', 'research', 'proposed', '.']], 'tgt': [['no', 'summary', 'found']]}]\u001b[0m\n",
            "\u001b[32m[]\u001b[0m\n",
            "\u001b[32m[('../json_data/cnndm.valid.0.json', Namespace(dataset='', log_file='../logs/preprocess.log', lower=True, map_path='../data/', max_nsents=100, max_src_ntokens=200, min_nsents=3, min_src_ntokens=5, mode='format_to_bert', n_cpus=4, oracle_mode='greedy', raw_path='../json_data', save_path='../json_data', shard_size=2000), '../json_data/cnndm.valid.0.bert.pt')]\u001b[0m\n",
            "\u001b[32m[2020-04-15 20:22:10,583 INFO] loading vocabulary file ../json_data/vocab.txt\u001b[0m\n",
            "\u001b[32m[2020-04-15 20:22:10,611 INFO] Processing ../json_data/cnndm.valid.0.json\u001b[0m\n",
            "\u001b[32m[2020-04-15 20:22:10,615 INFO] Saving to ../json_data/cnndm.valid.0.bert.pt\u001b[0m\n",
            "\u001b[32m[('../json_data/cnndm.test.0.json', Namespace(dataset='', log_file='../logs/preprocess.log', lower=True, map_path='../data/', max_nsents=100, max_src_ntokens=200, min_nsents=3, min_src_ntokens=5, mode='format_to_bert', n_cpus=4, oracle_mode='greedy', raw_path='../json_data', save_path='../json_data', shard_size=2000), '../json_data/cnndm.test.0.bert.pt')]\u001b[0m\n",
            "\u001b[32m[2020-04-15 20:22:10,693 INFO] loading vocabulary file ../json_data/vocab.txt\u001b[0m\n",
            "\u001b[32m[2020-04-15 20:22:10,720 INFO] Processing ../json_data/cnndm.test.0.json\u001b[0m\n",
            "\u001b[32m[2020-04-15 20:22:10,725 INFO] Saving to ../json_data/cnndm.test.0.bert.pt\u001b[0m\n",
            "\u001b[32mlook at me: ../json_data/cnndm test\u001b[0m\n",
            "\u001b[32mfiles found :  ['../json_data/cnndm.test.0.bert.pt']\u001b[0m\n",
            "\u001b[32mgpu_rank 0\u001b[0m\n",
            "\u001b[32m------------inside train.py test_iter---------------- <models.data_loader.Dataloader object at 0x7f56c63f5b00>\u001b[0m\n",
            "\u001b[32m---------------sent_scores-------------- tensor([[0.6225, 0.2962, 0.2188, 0.2055, 0.1864, 0.0588, 0.0510, 0.0561, 0.0258,\n",
            "         0.1015]])\u001b[0m\n",
            "\u001b[32m---------------mask--------------------- tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=torch.uint8)\u001b[0m\n",
            "\u001b[32m-----------------inside train.py pred------------------ ['numerical and asymptotic techniques will be used to investigate transonic flow about aircraft wings and flows with distributed vorticity .<q>specific transonic problems to be analyzed are design of optimum critical axisymmetric bodies , flows about lifting , not-so-slender transonic wings and the transonic area rule , and wind tunnel flows .<q>some use will be made of the transonic small disturbance formulation .']\u001b[0m\n",
            "\u001b[32m-----------------inside train.py gold------------------ ['no summary found']\u001b[0m\n",
            "\u001b[32m<_io.TextIOWrapper name='../json_data/results/_step50000.candidate' mode='w' encoding='ANSI_X3.4-1968'>\u001b[0m\n",
            "\u001b[32m-----combined----- numerical and asymptotic techniques will be used to investigate transonic flow about aircraft wings and flows with distributed vorticity .<q>specific transonic problems to be analyzed are design of optimum critical axisymmetric bodies , flows about lifting , not-so-slender transonic wings and the transonic area rule , and wind tunnel flows .<q>some use will be made of the transonic small disturbance formulation .\n",
            "\u001b[0m\n",
            "\u001b[32m---------------intermediate---------- numerical and asymptotic techniques will be used to investigate transonic flow about aircraft wings and flows with distributed vorticity .<q>specific transonic problems to be analyzed are design of optimum critical axisymmetric bodies , flows about lifting , not-so-slender transonic wings and the transonic area rule , and wind tunnel flows .<q>some use will be made of the transonic small disturbance formulation .\n",
            "\u001b[0m\n",
            "\u001b[32m------------in pretty summary----------------- numerical and asymptotic techniques will be used to investigate transonic flow about aircraft wings and flows with distributed vorticity .<q>specific transonic problems to be analyzed are design of optimum critical axisymmetric bodies , flows about lifting , not-so-slender transonic wings and the transonic area rule , and wind tunnel flows .<q>some use will be made of the transonic small disturbance formulation .\n",
            "\u001b[0m\n",
            "\u001b[32m------------------result------------- Numerical and asymptotic techniques will be used to investigate transonic flow about aircraft wings and flows with distributed vorticity. Specific transonic problems to be analyzed are design of optimum critical axisymmetric bodies , flows about lifting , not-so-slender transonic wings and the transonic area rule , and wind tunnel flows. Some use will be made of the transonic small disturbance formulation.\u001b[0m\n",
            "\u001b[32m169.254.255.130 - - [15/Apr/2020 20:22:11] \"#033[37mPOST /invocations HTTP/1.1#033[0m\" 200 -\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Batch Transform complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YThSIa-ehnGX",
        "colab_type": "text"
      },
      "source": [
        "## Output from Batch Transform\n",
        "\n",
        "Note: Ensure that the following package is installed on the local system : boto3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOehVNlDhnGX",
        "colab_type": "code",
        "outputId": "1dda1784-b3a7-4a4b-9820-955c43c55fbf",
        "colab": {}
      },
      "source": [
        "import boto3\n",
        "print(transformer.output_path)\n",
        "bucketFolder = transformer.output_path.rsplit('/')[3]\n",
        "#print(s3bucket,s3prefix)\n",
        "s3_conn = boto3.client(\"s3\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "s3://nsf/Summerized\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IelofWEDhnGZ",
        "colab_type": "code",
        "outputId": "c80e27bc-c3be-4fa7-d20c-1cdfb0b48481",
        "colab": {}
      },
      "source": [
        "bucket_name=\"nsf\"\n",
        "with open('result.txt', 'wb') as f:\n",
        "    s3_conn.download_fileobj(bucket_name,bucketFolder+'/top2.txt.out', f)\n",
        "    print(\"Output file loaded from bucket\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output file loaded from bucket\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShU-mX2fhnGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('./result.txt', 'rb') as file_stream:\n",
        "    output_text = file_stream.read().decode('utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2Ydu5tPhnGc",
        "colab_type": "text"
      },
      "source": [
        "#### Original Text Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC20mx4MhnGd",
        "colab_type": "code",
        "outputId": "3bdd6ae8-4deb-49ea-9b68-d04e5aa8062b",
        "colab": {}
      },
      "source": [
        "print(text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This research project will test four hypotheses about evolutionary forces that affect the behavior of pair-bonded birds to each other and to the nestlings they raise:1.male-male aggression during a female's fertile period decreases the likelihood that the female's young are sired by males other thanher territorial partner.2.female-female aggression during the egg-laying period functions to decrease the likelihood that females' broods contain nestlings from other females of the samespecies that lay their eggs in the nests of neighbors.3.mate- guarding by males is a response to females' behavior or ecological circumstances that increase the likelihood thatfemales mate with more than one male.4.parental feeding ofnestlings by males varies according to males' likelihood of genetic paternity as indicated by the behavior of females whenthey are fertile. these are important questions for several reasons.dr. gowatyand her colleagues are attempting to observe evolutionary processes as they occur, by testing the current functionalutility and evolutionary significance of important, sometimes dramatic, social behaviors.also, the researchers are testinghypotheses about the relationship of \"confidence of paternity\"(the perceived likelihood that a male is the actual genetic sireof the offspring he cares for) to actual genetic paternity as assessed using dna markers.this in turn is important becauseideas about confidence of paternity are theoretically prominent explanations for variation in the social behavior of male animals.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL2o6hDqhnGf",
        "colab_type": "text"
      },
      "source": [
        "#### Similar abstract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fnb5-1ShnGg",
        "colab_type": "code",
        "outputId": "b86d3fe5-feed-4588-c3e7-33520c8ca5f0",
        "colab": {}
      },
      "source": [
        "bucket_name=\"nsf\"\n",
        "with open('top1.txt', 'wb') as f:\n",
        "    s3_conn.download_fileobj(bucket_name,'top2.txt', f)\n",
        "    print(\"Output file loaded from bucket\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output file loaded from bucket\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyr6R3KXhnGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('./top2.txt', 'rb') as file_stream:\n",
        "    input_text = file_stream.read().decode('utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je59I3LQhnGj",
        "colab_type": "code",
        "outputId": "882fc12a-fead-4bcf-c6cf-6130f0dd9a4f",
        "colab": {}
      },
      "source": [
        "print(input_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "numerical and asymptotic techniques will be used to                        investigate transonic flow about aircraft wings and flows with                  distributed vorticity.  specific transonic problems to be                       analyzed are design of optimum critical axisymmetric bodies,                    flows about lifting, not-so-slender transonic wings and the                     transonic area rule, and wind tunnel flows.  some use will be                   made of the transonic small disturbance formulation.  the                       investigations of the vortical flow problem will involve                        development and clarification of theories integrating nonlinear                 and viscous effects.  both the transonic and vortical flow                      problems require interaction between numerical and asymptotic                   treatments in order to deal with complex nonlinearities.                             present day commercial aircraft cruise in the transonic                    regime.  in this regime drag (the force opposing forward motion)                rises rapidly hence there is interest in understanding transonic                flows and in the design of reduced drag wings.  the study of                    flows with distributed vorticity (a certain distribution of                     whirl-like motion in the environment of interest) is both of a                  fundamental nature in fluid mechanics, but also of considerable                 interest in specific applications.  one example of such an                      application is the prediction of aerodynamic losses and heat                    loads in turbo-machinery.  the investigators will use modern                    methods of applied mathematics to deal with the complexities of                 the problems in the areas of research proposed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyNXd1R8hnGl",
        "colab_type": "text"
      },
      "source": [
        "#### Summary of similar abstract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLaDnrJjhnGm",
        "colab_type": "code",
        "outputId": "563a5a21-492f-42a1-ec89-8de7dbbf2e6b",
        "colab": {}
      },
      "source": [
        "print(output_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numerical and asymptotic techniques will be used to investigate transonic flow about aircraft wings and flows with distributed vorticity. Specific transonic problems to be analyzed are design of optimum critical axisymmetric bodies , flows about lifting , not-so-slender transonic wings and the transonic area rule , and wind tunnel flows. Some use will be made of the transonic small disturbance formulation.\n",
            "Execution time : 1.40seconds\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4aIePLvhnGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9ymEMqQhnGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}